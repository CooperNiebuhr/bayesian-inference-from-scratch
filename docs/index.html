<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bayesian Logistic Regression from First Principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="bayes-logreg_files/libs/clipboard/clipboard.min.js"></script>
<script src="bayes-logreg_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="bayes-logreg_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="bayes-logreg_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="bayes-logreg_files/libs/quarto-html/popper.min.js"></script>
<script src="bayes-logreg_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="bayes-logreg_files/libs/quarto-html/anchor.min.js"></script>
<link href="bayes-logreg_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="bayes-logreg_files/libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="bayes-logreg_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="bayes-logreg_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="bayes-logreg_files/libs/bootstrap/bootstrap-9e3ffae467580fdb927a41352e75a2e0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#setup-and-synthetic-data" id="toc-setup-and-synthetic-data" class="nav-link" data-scroll-target="#setup-and-synthetic-data">Setup and synthetic data</a></li>
  <li><a href="#map-estimation-via-newtons-method" id="toc-map-estimation-via-newtons-method" class="nav-link" data-scroll-target="#map-estimation-via-newtons-method">MAP estimation via Newton’s method</a></li>
  <li><a href="#posterior-uncertainty-via-the-laplace-approximation" id="toc-posterior-uncertainty-via-the-laplace-approximation" class="nav-link" data-scroll-target="#posterior-uncertainty-via-the-laplace-approximation">Posterior uncertainty via the Laplace approximation</a></li>
  <li><a href="#posterior-predictive-inference" id="toc-posterior-predictive-inference" class="nav-link" data-scroll-target="#posterior-predictive-inference">Posterior predictive inference</a></li>
  <li><a href="#complete-example-with-visualization" id="toc-complete-example-with-visualization" class="nav-link" data-scroll-target="#complete-example-with-visualization">Complete example with visualization</a></li>
  <li><a href="#comparison-with-pymc" id="toc-comparison-with-pymc" class="nav-link" data-scroll-target="#comparison-with-pymc">Comparison with PyMC</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Bayesian Logistic Regression from First Principles</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>This notebook demonstrates a <strong>from-scratch implementation of Bayesian logistic regression</strong> using NumPy, with posterior uncertainty quantified via the Laplace approximation. The implementation includes numerically stable likelihood computations, Newton optimization for MAP estimation, and Monte Carlo integration for predictive inference.</p>
<p><strong>Key highlights:</strong> - Complete derivation and implementation of the posterior (prior + likelihood) - MAP estimation via Newton’s method with line search - Laplace approximation for posterior uncertainty - Posterior predictive distributions via Monte Carlo sampling - Validation against PyMC’s NUTS sampler</p>
<p><strong>If you have limited time:</strong> Jump to the <strong>Comparison with PyMC</strong> section to see how the from-scratch implementation matches a state-of-the-art probabilistic programming framework.</p>
<p><strong>Future directions:</strong> Planned extensions include full posterior sampling via Hamiltonian Monte Carlo and hierarchical Bayesian models with varying intercepts.</p>
</section>
<section id="setup-and-synthetic-data" class="level2">
<h2 class="anchored" data-anchor-id="setup-and-synthetic-data">Setup and synthetic data</h2>
<p>I generate a well-separated binary classification dataset with two classes of 100 points each. The classes are centered at (-2, 0) and (2, 0) with unit variance. An intercept column is added to enable a bias term in the logistic model.</p>
<p>This controlled setting makes it straightforward to visualize decision boundaries and verify that the implementation behaves correctly. All randomness is seeded for full reproducibility.</p>
<div id="5bece689" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">0</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>n0 <span class="op">=</span> n1 <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>X0 <span class="op">=</span> rng.normal(size<span class="op">=</span>(n0,<span class="dv">2</span>)) <span class="op">+</span> np.array([<span class="op">-</span><span class="fl">2.0</span>,<span class="fl">0.0</span>])</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> rng.normal(size<span class="op">=</span>(n1,<span class="dv">2</span>)) <span class="op">+</span> np.array([<span class="fl">2.0</span>,<span class="fl">0.0</span>])</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack([X0,X1])</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.c_[np.ones(<span class="bu">len</span>(X)),X]  <span class="co"># add intercept</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.r_[np.zeros(n0), np.ones(n1)]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="map-estimation-via-newtons-method" class="level2">
<h2 class="anchored" data-anchor-id="map-estimation-via-newtons-method">MAP estimation via Newton’s method</h2>
<p>The maximum a posteriori (MAP) estimate maximizes the log posterior, which combines a Gaussian prior on the weights with the logistic likelihood:</p>
<p><span class="math display">\[\log p(w \mid D) \propto \log p(D \mid w) + \log p(w)\]</span></p>
<p>For logistic regression with a Gaussian prior, the log posterior is strictly concave, guaranteeing a unique global maximum. Newton’s method exploits this structure by using exact second-order curvature information (the Hessian) to converge rapidly—typically in fewer than 10 iterations.</p>
<p>The implementation includes a backtracking line search to ensure each step increases the log posterior, making the optimizer robust even with poor initializations.</p>
<div id="059dd568" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bayes_fp <span class="im">import</span> newton_map_logistic</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>w_hat, H_hat, info <span class="op">=</span> newton_map_logistic(X, y, sigma0<span class="op">=</span><span class="fl">0.5</span>, verbose<span class="op">=</span><span class="va">True</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>iter 1 lp=-139.306810 ||step||=8.050e-01 t=1.00e+00
iter 2 lp=-48.057961 ||step||=5.374e-01 t=1.00e+00
iter 3 lp=-30.558037 ||step||=4.434e-01 t=1.00e+00
iter 4 lp=-25.852892 ||step||=2.197e-01 t=1.00e+00
iter 5 lp=-25.288095 ||step||=3.531e-02 t=1.00e+00
iter 6 lp=-25.277596 ||step||=7.188e-04 t=1.00e+00
iter 7 lp=-25.277592 ||step||=2.874e-07 t=1.00e+00</code></pre>
</div>
</div>
<p>The function returns: - <code>w_hat</code>: the MAP estimate - <code>H_hat</code>: the Hessian at the MAP (needed for the Laplace approximation) - <code>info</code>: a dictionary with convergence diagnostics</p>
</section>
<section id="posterior-uncertainty-via-the-laplace-approximation" class="level2">
<h2 class="anchored" data-anchor-id="posterior-uncertainty-via-the-laplace-approximation">Posterior uncertainty via the Laplace approximation</h2>
<p>A point estimate alone doesn’t capture parameter uncertainty. The Laplace approximation provides a Gaussian approximation to the posterior by taking a second-order Taylor expansion of the log posterior around the MAP:</p>
<p><span class="math display">\[p(w \mid D) \approx \mathcal{N}(w_{\text{MAP}}, \Sigma)\]</span></p>
<p>where <span class="math inline">\(\Sigma = -H^{-1}\)</span> and <span class="math inline">\(H\)</span> is the Hessian of the log posterior evaluated at the MAP. This approximation is exact for Gaussian posteriors and works well when the posterior is unimodal and approximately symmetric.</p>
<p>The key advantage is computational efficiency: we reuse the Hessian from optimization rather than running expensive sampling algorithms.</p>
<div id="24b19e2b" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bayes_fp <span class="im">import</span> laplace_covariance</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>Sigma <span class="op">=</span> laplace_covariance(H_hat)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="posterior-predictive-inference" class="level2">
<h2 class="anchored" data-anchor-id="posterior-predictive-inference">Posterior predictive inference</h2>
<p>Rather than making predictions with a single weight vector, Bayesian inference propagates uncertainty through to predictions via the <strong>posterior predictive distribution</strong>:</p>
<p><span class="math display">\[p(y_{\text{new}} = 1 \mid x_{\text{new}}, D) = \int \sigma(x_{\text{new}}^T w) \, p(w \mid D) \, dw\]</span></p>
<p>I approximate this integral via Monte Carlo: 1. Draw weight samples from the Laplace-approximated posterior 2. Compute predictions for each weight sample 3. Average the resulting probabilities</p>
<p>This produces smoother, better-calibrated predictions than using the MAP estimate alone, especially in regions far from the training data where uncertainty is higher.</p>
<div id="780657c4" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bayes_fp <span class="im">import</span> predictive_laplace_mc</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> predictive_laplace_mc(Xnew, w_hat, Sigma, nsamples<span class="op">=</span><span class="dv">5000</span>, seed<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="complete-example-with-visualization" class="level2">
<h2 class="anchored" data-anchor-id="complete-example-with-visualization">Complete example with visualization</h2>
<p>Here’s the full pipeline in action: data generation, MAP estimation, Laplace approximation, and posterior predictive inference at three test points.</p>
<div id="9e13c103" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bayes_fp <span class="im">import</span> newton_map_logistic, laplace_covariance, predictive_laplace_mc</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">0</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>n0 <span class="op">=</span> n1 <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>X0 <span class="op">=</span> rng.normal(size<span class="op">=</span>(n0,<span class="dv">2</span>)) <span class="op">+</span> np.array([<span class="op">-</span><span class="fl">2.0</span>,<span class="fl">0.0</span>])</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> rng.normal(size<span class="op">=</span>(n1,<span class="dv">2</span>)) <span class="op">+</span> np.array([<span class="fl">2.0</span>,<span class="fl">0.0</span>])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack([X0,X1])</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.c_[np.ones(<span class="bu">len</span>(X)),X]</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.r_[np.zeros(n0), np.ones(n1)]</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>w_hat, H_hat, info <span class="op">=</span> newton_map_logistic(X, y, sigma0<span class="op">=</span><span class="fl">0.5</span>, verbose<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>Sigma <span class="op">=</span> laplace_covariance(H_hat)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions at three test locations</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>Xnew <span class="op">=</span> np.c_[np.ones(<span class="dv">3</span>), np.array([[<span class="op">-</span><span class="dv">3</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">3</span>, <span class="dv">0</span>]])]</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> predictive_laplace_mc(Xnew, w_hat, Sigma, nsamples<span class="op">=</span><span class="dv">5000</span>, seed<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted probabilities at new locations:"</span>, probabilities)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MAP estimate:"</span>, w_hat)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>iter 1 lp=-139.306810 ||step||=8.050e-01 t=1.00e+00
iter 2 lp=-48.057961 ||step||=5.374e-01 t=1.00e+00
iter 3 lp=-30.558037 ||step||=4.434e-01 t=1.00e+00
iter 4 lp=-25.852892 ||step||=2.197e-01 t=1.00e+00
iter 5 lp=-25.288095 ||step||=3.531e-02 t=1.00e+00
iter 6 lp=-25.277596 ||step||=7.188e-04 t=1.00e+00
iter 7 lp=-25.277592 ||step||=2.874e-07 t=1.00e+00
Predicted probabilities at new locations: [0.00362788 0.53624058 0.99728352]
MAP estimate: [ 0.15209971  2.02803149 -0.17091209]</code></pre>
</div>
</div>
<p>The visualization below shows the posterior predictive probability surface across the input space. The decision boundary (0.5 contour) cleanly separates the two classes, and uncertainty increases smoothly in regions far from the training data.</p>
<div id="3990aaf3" class="cell" data-cache="true" data-execution_count="6">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="bayes-logreg_files/figure-html/cell-7-output-1.png" width="521" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Converged: True in 7 iterations
MAP: [ 0.1521  2.028  -0.1709]</code></pre>
</div>
</div>
</section>
<section id="comparison-with-pymc" class="level2">
<h2 class="anchored" data-anchor-id="comparison-with-pymc">Comparison with PyMC</h2>
<p>To validate the implementation, I fit an identical model using PyMC with the No-U-Turn Sampler (NUTS), a state-of-the-art Hamiltonian Monte Carlo algorithm. The model uses the same Gaussian prior (<span class="math inline">\(w \sim \mathcal{N}(0, 0.5^2 I)\)</span>) and Bernoulli likelihood.</p>
<p>For this well-behaved problem, the Laplace approximation is expected to work extremely well: the posterior is unimodal, concentrated, and close to Gaussian. Under these conditions, a second-order Taylor expansion captures nearly all the posterior mass, and the approximation <span class="math inline">\(p(w \mid D) \approx \mathcal{N}(w_{\text{MAP}}, \Sigma)\)</span> is highly accurate.</p>
<div id="39300fae" class="cell" data-cache="true" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> pymc_logreg:</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    sigma0 <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> pm.Normal(<span class="st">"w"</span>, mu<span class="op">=</span><span class="fl">0.0</span>, sigma<span class="op">=</span>sigma0, shape<span class="op">=</span>X.shape[<span class="dv">1</span>])</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    logit_p <span class="op">=</span> pm.math.dot(X, w)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    y_obs <span class="op">=</span> pm.Bernoulli(<span class="st">"y_obs"</span>, logit_p<span class="op">=</span>logit_p, observed<span class="op">=</span>y)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample(</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        draws<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        tune<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        chains<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        target_accept<span class="op">=</span><span class="fl">0.9</span>,</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        random_seed<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        return_inferencedata<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(az.summary(idata, var_names<span class="op">=</span>[<span class="st">"w"</span>], round_to<span class="op">=</span><span class="dv">3</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b49ba23a97cb48e78a8424e735e60b9e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>       mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \
w[0]  0.158  0.289  -0.420    0.663      0.005    0.004  3664.797  3013.450   
w[1]  2.100  0.252   1.638    2.585      0.004    0.004  3468.737  2991.188   
w[2] -0.168  0.265  -0.646    0.350      0.005    0.004  3315.642  2787.848   

      r_hat  
w[0]  1.001  
w[1]  1.000  
w[2]  1.001  </code></pre>
</div>
</div>
<p>The comparison reveals excellent agreement. The PyMC posterior mean is nearly identical to the MAP estimate (differences are negligible relative to coefficient magnitudes), and the decision boundaries overlap almost perfectly. This confirms that:</p>
<ol type="1">
<li>The analytic gradient and Hessian implementations are correct</li>
<li>The Newton solver reliably finds the global optimum</li>
<li>The Laplace approximation faithfully captures the posterior for this dataset</li>
</ol>
<p>In more challenging settings—such as weak class separation, strong collinearity, or highly skewed posteriors—the Laplace approximation can break down, and full MCMC sampling becomes necessary. However, for well-behaved problems like this one, the Laplace approach provides an accurate and computationally efficient alternative.</p>
<div id="006de1d9" class="cell" data-cache="true" data-execution_count="9">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="bayes-logreg_files/figure-html/cell-10-output-1.png" width="513" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>This notebook implements Bayesian logistic regression from the ground up, demonstrating proficiency with:</p>
<ul>
<li><strong>Probabilistic modeling</strong>: Deriving and implementing Bayesian posteriors</li>
<li><strong>Numerical optimization</strong>: Newton’s method with line search for MAP estimation<br>
</li>
<li><strong>Uncertainty quantification</strong>: Laplace approximation and posterior predictive inference</li>
<li><strong>Scientific computing</strong>: Numerically stable implementations in NumPy</li>
<li><strong>Validation</strong>: Comparison against established probabilistic programming tools</li>
</ul>
<p>The close agreement with PyMC validates the implementation and highlights when computationally efficient approximations can substitute for full sampling algorithms. The modular code structure in <code>bayes_fp.py</code> makes it straightforward to extend this work to more complex models and inference methods.</p>
</section>

</main>
<!-- /main column -->
<script type="application/vnd.jupyter.widget-state+json">
{"state":{"4b02614c6c4e4b51a22ecb97e2bd9408":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b49ba23a97cb48e78a8424e735e60b9e":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_4b02614c6c4e4b51a22ecb97e2bd9408","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                  </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.787       3            14.35 draws/s    0:02:19   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.669       7            14.85 draws/s    0:02:14   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.840       7            15.18 draws/s    0:02:11   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.691       3            14.19 draws/s    0:02:20   0:00:00    \n                                                                                                                   \n</pre>\n","text/plain":"                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                 \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  ━━━━━━━━━━━━━━━━━━━━━━━━━   2000    0             0.787       3            14.35 draws/s    0:02:19   0:00:00    \n  ━━━━━━━━━━━━━━━━━━━━━━━━━   2000    0             0.669       7            14.85 draws/s    0:02:14   0:00:00    \n  ━━━━━━━━━━━━━━━━━━━━━━━━━   2000    0             0.840       7            15.18 draws/s    0:02:11   0:00:00    \n  ━━━━━━━━━━━━━━━━━━━━━━━━━   2000    0             0.691       3            14.19 draws/s    0:02:20   0:00:00    \n                                                                                                                   \n"},"metadata":{},"output_type":"display_data"}],"tabbable":null,"tooltip":null}}},"version_major":2,"version_minor":0}
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>